{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Concatenate, Reshape, Dense, Conv1D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_len = 16\n",
    "k_len = 16\n",
    "c_len = 16\n",
    "epochs = 20\n",
    "loss_threshold = 0.1\n",
    "learning_rate = 0.0008\n",
    "batch_size = 256\n",
    "samples = 2 ** 16\n",
    "batches = samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_input = Input(shape=(p_len,), name=\"plaintext\")\n",
    "k_input = Input(shape=(k_len,), name=\"key\")\n",
    "c_input = Input(shape=(c_len,), name=\"ciphertext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_inputs = [p_input, k_input]\n",
    "x = Concatenate(axis=1, name=\"alice_concatenate\")(alice_inputs)\n",
    "x = Dense(units=(32), activation=\"relu\", name=\"alice_dense\")(x)\n",
    "x = Reshape(target_shape=(32, 1), name=\"alice_reshape\")(x)\n",
    "x = Conv1D(filters=2, kernel_size=4, strides=1, padding=\"same\", activation=\"relu\", name=\"alice_conv1d_1\")(x)\n",
    "x = Conv1D(filters=4, kernel_size=2, strides=2, padding=\"same\", activation=\"relu\", name=\"alice_conv1d_2\")(x)\n",
    "x = Conv1D(filters=4, kernel_size=1, strides=1, padding=\"same\", activation=\"relu\", name=\"alice_conv1d_3\")(x)\n",
    "x = Conv1D(filters=1, kernel_size=1, strides=1, padding=\"same\", activation=\"tanh\", name=\"alice_conv1d_4\")(x)\n",
    "alice_outputs = Flatten(name=\"alice_flatten\")(x)\n",
    "alice = Model(inputs=alice_inputs, outputs=alice_outputs, name=\"alice\")\n",
    "alice.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_inputs = [c_input, k_input]\n",
    "x = Concatenate(axis=1, name=\"bob_concatenate\")(bob_inputs)\n",
    "x = Dense(units=(32), activation=\"relu\", name=\"bob_dense\")(x)\n",
    "x = Reshape(target_shape=(32, 1), name=\"bob_reshape\")(x)\n",
    "x = Conv1D(filters=2, kernel_size=4, strides=1, padding=\"same\", activation=\"relu\", name=\"bob_conv1d_1\")(x)\n",
    "x = Conv1D(filters=4, kernel_size=2, strides=2, padding=\"same\", activation=\"relu\", name=\"bob_conv1d_2\")(x)\n",
    "x = Conv1D(filters=4, kernel_size=1, strides=1, padding=\"same\", activation=\"relu\", name=\"bob_conv1d_3\")(x)\n",
    "x = Conv1D(filters=1, kernel_size=1, strides=1, padding=\"same\", activation=\"tanh\", name=\"bob_conv1d_4\")(x)\n",
    "bob_outputs = Flatten(name=\"bob_flatten\")(x)\n",
    "bob = Model(inputs=bob_inputs, outputs=bob_outputs, name=\"bob\")\n",
    "bob.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve_inputs = c_input\n",
    "x = Dense(units=(32), activation=\"relu\", name=\"eve_dense\")(eve_inputs)\n",
    "x = Reshape(target_shape=(32, 1), name=\"eve_reshape\")(x)\n",
    "x = Conv1D(filters=2, kernel_size=4, strides=1, padding=\"same\", activation=\"relu\", name=\"eve_conv1d_1\")(x)\n",
    "x = Conv1D(filters=4, kernel_size=2, strides=2, padding=\"same\", activation=\"relu\", name=\"eve_conv1d_2\")(x)\n",
    "x = Conv1D(filters=4, kernel_size=1, strides=1, padding=\"same\", activation=\"relu\", name=\"eve_conv1d_3\")(x)\n",
    "x = Conv1D(filters=1, kernel_size=1, strides=1, padding=\"same\", activation=\"tanh\", name=\"eve_conv1d_4\")(x)\n",
    "eve_outputs = Flatten(name=\"eve_flatten\")(x)\n",
    "eve = Model(inputs=eve_inputs, outputs=eve_outputs, name=\"eve\")\n",
    "eve.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 distance metric for loss\n",
    "def l1_distance(a, b):\n",
    "  a = (a + 1) / 2\n",
    "  b = (b + 1) / 2\n",
    "  return tf.reduce_mean(tf.reduce_sum(tf.abs(a - b), axis=-1))\n",
    "\n",
    "\n",
    "# create training batch\n",
    "def create_batch():\n",
    "  p_batch = np.random.choice([-1, 1], size=(batch_size, p_len))\n",
    "  k_batch = np.random.choice([-1, 1], size=(batch_size, k_len))\n",
    "  return p_batch, k_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single forward pass for symbolic links\n",
    "alice_output = alice([p_input, k_input])\n",
    "bob_output = bob([alice_output, k_input])\n",
    "eve_output = eve(alice_output)\n",
    "# loss and metric functions\n",
    "tn_eve_loss = l1_distance(p_input, eve_output)\n",
    "tn_alice_bob_loss = l1_distance(p_input, bob_output) + tf.square(p_len / 2 - tn_eve_loss) / ((p_len / 2) ** 2)\n",
    "tn_alice_bob_metric = l1_distance(p_input, bob_output)\n",
    "tn_eve_metric = l1_distance(p_input, eve_output)\n",
    "# create auxillary training networks\n",
    "tn_alice_bob = Model(inputs=[p_input, k_input], outputs=bob_output, name=\"tn_alice_bob\")\n",
    "tn_alice_bob.add_loss(tn_alice_bob_loss)\n",
    "tn_alice_bob.add_metric(tn_alice_bob_metric, name=\"l1_distance\")\n",
    "tn_eve = Model(inputs=[p_input, k_input], outputs=eve_output, name=\"tn_eve\")\n",
    "tn_eve.add_loss(tn_eve_loss)\n",
    "tn_eve.add_metric(tn_eve_metric, name=\"l1_distance\")\n",
    "tn_alice_bob.compile(Adam(learning_rate=learning_rate))\n",
    "alice.trainable = False\n",
    "tn_eve.compile(Adam(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_train_errors = []\n",
    "eve_train_errors = []\n",
    "\n",
    "epoch = 0\n",
    "above_threshold = True\n",
    "start_time = time.time()\n",
    "with tqdm(total=epochs*batches, desc=\"Training\", unit=\"batch\") as pbar:\n",
    "  while epoch < epochs and above_threshold:\n",
    "    for batch in range(batches):\n",
    "      p_batch, k_batch = create_batch()\n",
    "      tn_alice_bob.train_on_batch([p_batch, k_batch])\n",
    "      alice_bob_loss, bob_error = tn_alice_bob.evaluate([p_batch, k_batch], verbose=0)\n",
    "      bob_train_errors.append(bob_error)\n",
    "\n",
    "      # train Eve for 2 batches\n",
    "      for _ in range(2):\n",
    "        p_batch, k_batch = create_batch()\n",
    "        tn_eve.train_on_batch([p_batch, k_batch])\n",
    "      _, eve_error = tn_eve.evaluate([p_batch, k_batch], verbose=0)\n",
    "      eve_train_errors.append(eve_error)\n",
    "\n",
    "      # update progress bar\n",
    "      pbar.set_postfix({\"alice_bob_loss\": alice_bob_loss, \"bob_error\": bob_error, \"eve_error\": eve_error})\n",
    "      pbar.update()\n",
    "\n",
    "      # exit if Alice and Bob loss is below threshold\n",
    "      if alice_bob_loss < loss_threshold:\n",
    "        print(\"Minimum loss threshold reached, exiting early\")\n",
    "        above_threshold = False\n",
    "        break\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "total_time = time.strftime(\"%M:%S\", time.gmtime(time.time() - start_time))\n",
    "print(f\"Training finished ({total_time})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training errors\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(bob_train_errors, label=\"Bob\")\n",
    "plt.plot(eve_train_errors, label=\"Eve\")\n",
    "plt.title(f\"Symmetric model training errors\")\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(f\"Bits wrong (of {p_len})\")\n",
    "plt.yticks(np.arange(0, (p_len / 2) + 0.5, 0.5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save models\n",
    "# alice.save(\"models/symmetric/alice.keras\")\n",
    "# bob.save(\"models/symmetric/bob.keras\")\n",
    "# eve.save(\"models/symmetric/eve.keras\")\n",
    "# # load models\n",
    "# alice = keras.models.load_model(\"models/symmetric/alice.keras\")\n",
    "# bob = keras.models.load_model(\"models/symmetric/bob.keras\")\n",
    "# eve = keras.models.load_model(\"models/symmetric/eve.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_eval_errors = []\n",
    "eve_eval_errors = []\n",
    "\n",
    "start_time = time.time()\n",
    "with tqdm(total=batches, desc=\"Evaluation\", unit=\"batch\") as pbar:\n",
    "  for batch in range(batches):\n",
    "    p_batch, k_batch = create_batch()\n",
    "    alice_bob_loss, bob_error = tn_alice_bob.evaluate([p_batch, k_batch], verbose=0)\n",
    "    bob_eval_errors.append(bob_error)\n",
    "\n",
    "    p_batch, k_batch = create_batch()\n",
    "    _, eve_error = tn_eve.evaluate([p_batch, k_batch], verbose=0)\n",
    "    eve_eval_errors.append(eve_error)\n",
    "\n",
    "    # update progress bar\n",
    "    pbar.set_postfix({\"alice_bob_loss\": alice_bob_loss, \"bob_error\": bob_error, \"eve_error\": eve_error})\n",
    "    pbar.update()\n",
    "\n",
    "total_time = time.strftime(\"%M:%S\", time.gmtime(time.time() - start_time))\n",
    "print(f\"Evaluation finished ({total_time})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evaluation errors\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(bob_eval_errors, label=\"Bob\")\n",
    "plt.plot(eve_eval_errors, label=\"Eve\")\n",
    "plt.title(f\"Symmetric model evaluation errors\")\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(f\"Bits wrong (of {p_len})\")\n",
    "plt.yticks(np.arange(0, (p_len / 2) + 0.5, 0.5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text of utf-8 characters to tensor\n",
    "def text_to_tensor(text, p_len):\n",
    "  # convert single utf-8 character to 8-bit binary list\n",
    "  def char_to_binary(ch):\n",
    "    return [int(bit) for bit in format(ord(ch), \"08b\")]\n",
    "\n",
    "  binary = np.array([char_to_binary(ch) for ch in text]).flatten()\n",
    "  # pad binary list to multiple of p_len\n",
    "  pad = (p_len - len(binary) % p_len) % p_len\n",
    "  tensor = np.concatenate([(binary * 2) - 1, np.zeros(pad)])\n",
    "  return tensor, pad\n",
    "\n",
    "\n",
    "# convert tensor to text of utf-8 characters\n",
    "def tensor_to_text(tensor, pad):\n",
    "  # convert 8-bit binary list to single utf-8 character\n",
    "  def binary_to_char(binary):\n",
    "    return chr(int(\"\".join([str(bit) for bit in binary]), 2))\n",
    "\n",
    "  binary = np.round((tensor + 1) / 2.0).astype(\"int\").flatten()\n",
    "  binarys = [binary[i: i + 8] for i in range(0, len(binary) - pad, 8)]\n",
    "  return \"\".join(map(binary_to_char, binarys))\n",
    "\n",
    "\n",
    "# perform symmetric encryption/decryption on text using trained models\n",
    "def symmetric_encryption(plaintext):\n",
    "  tensor, pad = text_to_tensor(plaintext, p_len)\n",
    "  p_inputs = np.array(tensor).reshape(-1, p_len)\n",
    "  k_inputs = np.random.choice([-1, 1], size=(len(p_inputs), k_len))\n",
    "\n",
    "  alice_output = alice([p_inputs, k_inputs])\n",
    "  bob_output = bob([alice_output, k_inputs])\n",
    "  eve_output = eve(alice_output)\n",
    "\n",
    "  ciphertext = tensor_to_text(alice_output, pad)\n",
    "  plaintext_bob = tensor_to_text(bob_output, pad)\n",
    "  plaintext_eve = tensor_to_text(eve_output, pad)\n",
    "\n",
    "  return ciphertext, plaintext_bob, plaintext_eve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaintext = \"Hello, World!\"\n",
    "ciphertext, plaintext_bob, plaintext_eve = symmetric_encryption(plaintext)\n",
    "print(f\"Plaintext: {plaintext}\")\n",
    "print(f\"Ciphertext: {ciphertext}\")\n",
    "print(f\"Plaintext (Bob): {plaintext_bob}\")\n",
    "print(f\"Plaintext (Eve): {plaintext_eve}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac1fbcbc78a545fa59d68f87f1c082cbf7d3cb7726d6c83c85c56055d74e8653"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
